{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7238f360",
   "metadata": {},
   "source": [
    "# Title: Maximizing Customer Retention: A Churn Prediction Analysis The forÂ Vodafone Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57fc86",
   "metadata": {},
   "source": [
    "## Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81608074",
   "metadata": {},
   "source": [
    "Customer attrition is a prevalent problem for many businesses, resulting in large financial losses. We intend to investigate customer churn or attrition in this project, which refers to the percentage of consumers that discontinue using a company's product or service within a specified time frame. Understanding the primary causes of customer churn can assist businesses in developing effective retention strategies to reduce customer attrition and boost revenue.\n",
    "\n",
    "This project's dataset includes information about users' demographics, service usage, and billing information. We will use this dataset to conduct an exploratory data analysis in order to find patterns and trends linked to customer attrition. We will next use machine learning techniques to create a predictive model that will estimate the likelihood of a customer leaving the firm.\n",
    "\n",
    "__Our project's objectives are to:__\n",
    "\n",
    "1.Investigate and display the data to uncover patterns and trends in customer attrition.\n",
    "\n",
    "2.Using machine learning methods, create a predictive model to forecast the possibility of client attrition.\n",
    "\n",
    "3.Determine the major churn indicators, such as client demographics, service usage, and billing information.\n",
    "\n",
    "4.Create retention techniques to assist reduce client turnover while increasing customer loyalty.\n",
    "\n",
    "5.Based on the model's results, assess the success of retention efforts and make recommendations for changes.\n",
    "\n",
    "The project's outcome will provide valuable insights for Vodafone to understand customer churn and implement effective retention strategies to reduce customer attrition and increase revenue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5e6ee",
   "metadata": {},
   "source": [
    "## Hypothesis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87215ac0",
   "metadata": {},
   "source": [
    "Null hypothesis : \n",
    "\n",
    "Gender has a significant impact on churn for vodafone customers. \n",
    "\n",
    "Alternative hypothesis :\n",
    "\n",
    "Gender doesnot have a significant impact on churn for vodafone customers      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf139695",
   "metadata": {},
   "source": [
    "## Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0d756",
   "metadata": {},
   "source": [
    "1. Which age group (Senior Citizen Column) paid the highest monthly charges?\n",
    "2. Which gender has the highest count of churn ? \n",
    "3. Which Internet Service is patronized the most?\n",
    "4. How much total charge and monthly charge revenue does churners generate?\n",
    "5. Which payment method is the most popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8e065",
   "metadata": {},
   "source": [
    "## Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0edf5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##!pip install imblearn ##for handling imbalanace data\n",
    "##! pip install phik ##for our phik correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabed430",
   "metadata": {},
   "source": [
    "# Library Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns \n",
    "import random\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Feature Processing (Scikit-learn processing, etc. )\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "#Algorithms and pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "##handling imbalance datasets\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "##hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# statistic model\n",
    "import statsmodels.api as sm\n",
    "...\n",
    "\n",
    "# Other packages\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5287ced5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a422da42",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv('../LP2_Telco-churn-last-2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78498c63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##taking a look at our dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d72d7",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b155bf",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be91664",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d169f2",
   "metadata": {},
   "source": [
    "### Notes of .info():\n",
    "\n",
    "- Also, the TotalCharges column is an object data type, so we might want to check that. \n",
    "- There are no missing values\n",
    "- We have a total of 7043 rows \n",
    "- We have a total of 21 columns \n",
    "- Our target variable has  yes/no attributes, therefore it is a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de694899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bcd8f2",
   "metadata": {},
   "source": [
    "### __Key Notes__:\n",
    "\n",
    "__SeniorCitizen__: \n",
    "\n",
    "- This is a binary variable that indicates whether or not the customer is a senior citizen. \n",
    "\n",
    "- The output shows that out of 7,043 observations, 16.2% (or about 1,142) are senior citizens on average.\n",
    "\n",
    "__tenure__: \n",
    "\n",
    "- This variable represents the number of months the customer has been with the company. \n",
    "\n",
    "- The output shows that on average, customers have been with the company for 32.4 months, but the standard deviation is quite large (24.6 months), indicating that there is a wide range of values for this variable. \n",
    "\n",
    "- Less than 75% of the customers spend less than 55 months with the company.\n",
    "\n",
    "__MonthlyCharges__:  \n",
    "\n",
    "- This variable represents the amount the customer pays each month for the company's services. \n",
    "\n",
    "- The output shows that on average, customers pay \\\\$64.76 per month, with 75 percent paying less than  \\\\$89.85. \n",
    "\n",
    "- Again, the standard deviation is quite large (30.1 dollars), indicating that there is a wide range of values for this variable as well. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a4f615",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "since our total charges column is a object dataframe, we will be creating a copy of our dataset and use the copy for our EDA with our TotalCharges being converted to numeric. We will use the orginal frame for our modelling and build a pipeline which can handle everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's create a copy to make  it easy for us to revert to our original dataframe if we make a mistake\n",
    "\n",
    "df_copy= df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfeb350",
   "metadata": {},
   "source": [
    "### Converting the totalcharges column to a numerical variable\n",
    "\n",
    "from .info(), we realized that the TotalCharge feature was an object data type; however, looking at it, it was an object, there we willbe chaning it to a numeric data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd505c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[\"TotalCharges\"]= pd.to_numeric(df_copy[\"TotalCharges\"], errors= \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8b84d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Let's check to see if there are any further missing values\n",
    "\n",
    "df_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de830a",
   "metadata": {},
   "source": [
    "there are 11 missing values so we will replace them with the mean of the TotalCharges column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaebb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[\"TotalCharges\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b89221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.fillna(value= df_copy[\"TotalCharges\"].mean(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e8bde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Let's check again for missing values\n",
    "df_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since there are no more missing values, we can proceed to use the df_copy for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We will like to drop our ID column for both dataset since it composes of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(\"customerID\", axis= 1)\n",
    "\n",
    "df_copy= df_copy.drop(\"customerID\", axis= 1)\n",
    "\n",
    "##Note we will be using the df_copy for our analysis and the df for our modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9776456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I am saving it so that I can use it for power BI:\n",
    "\n",
    "df_copy.to_csv(\"Documents/Vodafone_churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4384f92",
   "metadata": {},
   "source": [
    "## Univariate Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43440859",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Let's take a look at the distrubution of the columns \n",
    "##this our funciton allows you to plot any number of columns \n",
    "\n",
    "def plot_distribution(df,cols):\n",
    "    for col in cols:\n",
    "        sns.displot(df[col],kde= True)\n",
    "        plt.figure(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d009eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##we are using the function above to plot the distrubution of the columns below\n",
    "plot_distribution(df_copy, ['SeniorCitizen', 'tenure', 'MonthlyCharges']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f488ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d53b5d",
   "metadata": {},
   "source": [
    "__Observations__:\n",
    "\n",
    "- Most customers for vodafone are non-senior citizens\n",
    "\n",
    "- Most customers pay a monthly charge of 20 units \n",
    "\n",
    "- Most customers stay on the network for 0 months, and 70 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "##checking for outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734105b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=df_copy);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d11d0",
   "metadata": {},
   "source": [
    "##### Observation:\n",
    "\n",
    "- It can be seen that there are no outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679bd39",
   "metadata": {},
   "source": [
    "### Univariate on the Churn Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa46bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##the idea here is to check to see the ratio of our label variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2bb62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##sns.countplot(x = df_copy[\"Churn\"], data = df_copy)\n",
    "##plt.title(\"Plot of Ratio of the Label Variables(Churn)\")\n",
    "\n",
    "fig = px.pie(df_copy, names='Churn', title='Plot of Ratio of the Label Variables (Churn)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2592e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's see the percentage\n",
    "\n",
    "count= df_copy[\"Churn\"].value_counts()\n",
    "\n",
    "percen= count/len(df_copy[\"Churn\"]) *100\n",
    "print(\"The percentage of No is: \", round(percen[0], 2))\n",
    "print(\"The percentage of Yes is: \", round(percen[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "percen[0]/percen[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dc8e47",
   "metadata": {},
   "source": [
    "#### Notes from exploring the Label Variable:\n",
    "\n",
    "- We can see there is an imbalance in our dataset; therefore we will have to deal with that.\n",
    "\n",
    "- 73% of the vodafone customers are still loyal\n",
    "\n",
    "- 26.54% of the customers in the current dataset have left the company \n",
    "\n",
    "- Those who are still in the company are 2.77 times larger than those who have left "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f04a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_copy.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90888ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##We can see the tenure has 73 unique values, therefore it will be a good idea to bin it up to help make our analysis easier.\n",
    "\n",
    "labels= [\"{0} - {1}\".format(i,i+11) for i in range (0, 73, 12) ]\n",
    "\n",
    "df_copy[\"tenure_group\"]= pd.cut(df_copy.tenure, range(1, 80, 12), right= False, labels=labels[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d0677",
   "metadata": {},
   "source": [
    "#### We are Trying to visualize to see how each categorical column variaes with Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41b999",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for  col in df_copy.drop([\"Churn\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"], axis= 1):\n",
    "    fig= px.histogram(df_copy, color= \"Churn\", x= col, title= f\"Count of {col}, with respect to Churn\", \n",
    "                      color_discrete_sequence=random.sample([\"red\", \"pink\", \"blue\", \"green\"], k=2))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566baee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Since there is an unequal number of both attributes, it will be a good idea to see how they vary based on percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283b5bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##in this code, we are checking to see the churn YES to NO churn percentage of each categorical feature\n",
    "\n",
    "for col in df_copy.drop([\"Churn\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"], axis= 1):\n",
    "    churn_by_col = df_copy.groupby(col)['Churn'].value_counts(normalize=True).mul(100).rename('percent').reset_index()\n",
    "    fig = px.bar(churn_by_col, x=col, y='percent',color=\"Churn\", text='percent', title= f\"Percentage of: {col} with respect to Churn\", \n",
    "                      color_discrete_sequence=random.sample([\"chartreuse\",\"darkblue\",\"darkviolet\",\"aqua\", \"aquamarine\", \"beige\", \"burlywood\"], k=2) )\n",
    "    fig.update_traces(texttemplate='%{text:.2f}%', textposition='outside')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b18e6",
   "metadata": {},
   "source": [
    "### Notes after Analysis:\n",
    "\n",
    "- Individuals with 0 to 11 months of use are most likely to churn\n",
    "- Individuals with electronic checks churn the most \n",
    "- Individuals on the fiber optics plan had the highest churn\n",
    "- Female customers churned more than male customers \n",
    "- Even though there were more non senior citizens than senior citizens (from our count plot), senior citizens churned more percentage-wise. This could be because of old age, death or other factors. \n",
    "- Customers with no dependents are most likely to churn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ed3b0",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f59682",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Let's see the relationship between monthly charges and totalcharges. We will like to see if total charges increase \n",
    "with Monthlycharges \"\"\"\n",
    "\n",
    "px.scatter(df_copy, x=\"MonthlyCharges\", y= \"TotalCharges\", color_discrete_sequence=[\"chartreuse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677f39b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Let's see the relationship between TotalCharges and tenure, how does one using the network for long affec their total charge\n",
    "\n",
    "px.scatter(df_copy, x=\"tenure\", y= \"TotalCharges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4cdcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Let's see which age group is most likely to pay the highest totalcharges\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.barplot(x=\"SeniorCitizen\", y=\"TotalCharges\", data=df_copy, palette= \"pastel\")\n",
    "plt.title(\"Average Total Charges of the SeniorCitizens Column\")\n",
    "#plt.xticks(rotation=90)\n",
    "plt.figure(figsize= (20,15))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595147f",
   "metadata": {},
   "source": [
    "#### Notes From Bivariate Analysis:\n",
    "\n",
    "- We can see that total charges and monthly charges have a positive correlation. Therefore, the more monthly charges a customer pays, the more likely their totalcharge will increase \n",
    "\n",
    "- Also, total charges and tenure has a positive correlation. Therefore, the more time (tenure) a customer spends the more total charges they pay \n",
    "\n",
    "- Also, on average, senior citzens are paying a higher total charge than non-senior citizens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc9ec3",
   "metadata": {},
   "source": [
    "### Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311b3e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_copy.corr(), annot= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730b4dd",
   "metadata": {},
   "source": [
    "## Answering Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb1a9a",
   "metadata": {},
   "source": [
    "We will be answering the questions below:\n",
    "\n",
    "1. Which age group paid the highest total charge?\n",
    "2. Which gender has the highest count of churn ? \n",
    "3. Which Internet Service is patronized the most?\n",
    "4. How much total charge and monthly charge revenue does churners generate?\n",
    "5. Which payment method is the most popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95316710",
   "metadata": {},
   "source": [
    "#### Question 1: Which Age Group paid the highest Monthly Charges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead9800",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##The only age group given to us was the seniors column, therefore, we will see the amount each group paid \n",
    "\n",
    "sum_agegroup= df_copy.groupby(\"SeniorCitizen\").agg({\"TotalCharges\": \"sum\"}).reset_index()\n",
    "\n",
    "sns.barplot(x= \"SeniorCitizen\", y= \"TotalCharges\", data= sum_agegroup, palette= \"colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f566da",
   "metadata": {},
   "source": [
    "#### Answer to Question1:\n",
    "\n",
    "- From the chart above, we can see that non-senior citizens spend more money (interms of total charges) than senior citizens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1bdda0",
   "metadata": {},
   "source": [
    "#### Question 2: Which Gender Recorded the highest Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "churners= df_copy[df_copy[\"Churn\"]== \"Yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(x=\"gender\", data_frame=churners, color= \"gender\", color_discrete_sequence=[\"teal\", \"grey\"], title= \"Plot of the Occurence Of Churn Across the Various Gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765f9dc3",
   "metadata": {},
   "source": [
    "#### Answer to Question2:\n",
    "- Females tend to churn more than males "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7bc88",
   "metadata": {},
   "source": [
    "### Question 3: Which Internet Service Is Patronized The Most?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b084bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_count= df.InternetService.value_counts().to_frame(name= \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0a206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "internet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(internet_count, x=internet_count.index, y='count', size='count', color= internet_count.index, hover_name=internet_count.index,\n",
    "                 log_y=False, size_max=60, title= \"Plot of The Popularity Of The Various Internet Services\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e75309",
   "metadata": {},
   "source": [
    "#### Answer to Question3:\n",
    "\n",
    "- Fiber Options was the most patronized Internet Service "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d091d22",
   "metadata": {},
   "source": [
    "#### Question 4: How much total charge and monthly charge revenue does churners generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "##since we are looking at churners, we will use the churners dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "money= churners.agg({\"MonthlyCharges\": \"sum\", \"TotalCharges\": \"sum\"}).reset_index()\n",
    "\n",
    "money.columns= [\"Charge\", \"Amount\"]\n",
    "\n",
    "px.bar(data_frame= money, x= \"Charge\",\n",
    "       \n",
    "       y= \"Amount\", title= \"Amount Paid By Churners In Terms\", text= \"Amount\", color= \"Charge\", color_discrete_sequence= [\"yellow\", \"black\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7973bf4a",
   "metadata": {},
   "source": [
    "#### Answer to Question 4:\n",
    "\n",
    "From the dataframe above, we can see that customers that churned generataed a whooping \\\\$139130 in monthly charges and \\\\$2,862,927 in total charges. This means Vodafone is losing \\\\$139130 monthly and a total of \\\\$2,862,927 due to Churns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd57140e",
   "metadata": {},
   "source": [
    "#### Question 5: Which payment method is the most popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225597be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"PaymentMethod\", data=df, palette= \"pastel\"  )\n",
    "plt.title(\"Plot of Counts of Various Payment Methods\")\n",
    "plt.xticks(rotation= 45)\n",
    "plt.figure(figsize= (15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9229b3e6",
   "metadata": {},
   "source": [
    "#### Answer to Question 5:\n",
    "- We can see that electronic Check is the most popular payment method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba000464",
   "metadata": {},
   "source": [
    "### Note:\n",
    "\n",
    "- Now we are done with our analysis, therefore, we will be using our df for our modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad043d7e",
   "metadata": {},
   "source": [
    "## Primary Feature Selection:\n",
    "\n",
    "- in this section we will be selecting the best features for our algorithm. We will be using the Phi-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9465114",
   "metadata": {},
   "outputs": [],
   "source": [
    "##getting the correlation of other features with churn\n",
    "\n",
    "churn_corr= df.phik_matrix().loc[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193bdb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "##sorting the values \n",
    "churn_cor=churn_corr.sort_values()\n",
    "\n",
    "churn_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e02e5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##ploting the phi-k correlation mattress\n",
    "sns.heatmap(churn_cor.to_frame(), annot= True, cmap= \"coolwarm\")\n",
    "\n",
    "plt.title(\"Phi_k Correlation Matrix for all  Features\")\n",
    "\n",
    "plt.figure(figsize= (10,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1bc0df",
   "metadata": {},
   "source": [
    "From our feature selection, we will be dropping columns with correlation coeeficient less than 0.2:\n",
    "    \n",
    "    - Gender\n",
    "    - PhoneService\n",
    "    - MultipleLines\n",
    "  \n",
    "    \n",
    "    \n",
    "Since they have a correlation less than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop= df.drop([\"gender\", \"PhoneService\", \"MultipleLines\"], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165aafa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea06cd",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39f93e",
   "metadata": {},
   "source": [
    "Note:\n",
    "- We will be using the df_drop dataframe for our analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0d1d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_drop.replace(r'^\\s*$', np.nan, regex=True).isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fda7c",
   "metadata": {},
   "source": [
    "### Step 1: Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a984bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6be116",
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating our features and label\n",
    "\n",
    "X= df_drop.drop(\"Churn\", axis=1)\n",
    "y= df_drop.Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###converting our label to a numeric variable for easy analysis \n",
    "\n",
    "LE= LabelEncoder() ##initializing the model\n",
    "\n",
    "\n",
    "num_y_train= LE.fit_transform(y_train) ##fitting and transforming on the train data\n",
    "\n",
    "num_y_test= LE.transform(y_test) ##transforming on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb5957",
   "metadata": {},
   "source": [
    "### Step 2: Creating Our Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27084822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##getting our categorical attributes \n",
    "cat_attr= [i for i in df_drop.drop([\"TotalCharges\", \"MonthlyCharges\", \"tenure\", \"Churn\"], axis= 1)]\n",
    "\n",
    "\n",
    "##getting our numerical attributes\n",
    "num_attr= [\"TotalCharges\", \"MonthlyCharges\", \"tenure\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7020b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb889a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53254b",
   "metadata": {},
   "source": [
    "### Step 3: Creating Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf55413",
   "metadata": {},
   "source": [
    "#### Creating numeric pipeline\n",
    "\n",
    "##### For Our Empty Rows:\n",
    "\n",
    "- We will create a function to handle that\n",
    "\n",
    "##### For our numeric values, we need to:\n",
    "\n",
    "- Scale since our monthly transaction and total transaction are of different magnitudes and also since we will be using models sensitive to unscaled values.\n",
    "\n",
    "- Also, we will create a function to handle the missing values in the numeric attribute. \n",
    "\n",
    "\n",
    "##### For our categorical \n",
    "\n",
    "- We will need to transform our categorical features to numeric using a onehotencoder\n",
    "- We will also handle data in balance using Sklearns class_balance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### handling the empty space. The aim of the this function is to replace the missing values with NaN values\n",
    "\n",
    "def remove_space(in_df):\n",
    "    in_df[\"TotalCharges\"]= in_df[\"TotalCharges\"].replace(r\"^\\s*$\", np.nan, regex= True)\n",
    "    return in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c4de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Since we cannot fit and transform the function above, we will create a class with the function embedded to help \n",
    "\n",
    "us call, fit, and transform with the function above\"\"\"\n",
    "\n",
    "class SpaceImputer():\n",
    "    def __init__(self,func):\n",
    "        self.func= func\n",
    "    \n",
    "    def transform(self, in_df, **transform_params):\n",
    "        return self.func(in_df)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897e1c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This pipeline will handle the nan values in our dataset and also standardize our\n",
    "\n",
    "## we are using mean because from our previous analysis, there were no outliers\n",
    "\n",
    "num_pipeline= Pipeline([(\"mean_imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "cat_pipeline= Pipeline([(\"one_hot\", OneHotEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8577200",
   "metadata": {},
   "outputs": [],
   "source": [
    "##we are combining our numeric and categorical pipelines with a Columntransformer\n",
    "\n",
    "col_pipe= ColumnTransformer([(\"num_pipe\", num_pipeline, num_attr),(\"cat_pipe\", cat_pipeline, cat_attr)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a62c0a",
   "metadata": {},
   "source": [
    "### Creating a pipeline for each Classifier (ML Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a32f3",
   "metadata": {},
   "source": [
    "#### DecisionTree CLassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DTP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "              (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "              (\"model\", DecisionTreeClassifier(random_state= 100))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1= DTP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(num_y_test,result_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fdb244",
   "metadata": {},
   "source": [
    "#### Logistic Regressor Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a827e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LRP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "              (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "              (\"model\", LogisticRegression(random_state= 100))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2= LRP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test,result_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a7cb6",
   "metadata": {},
   "source": [
    "#### Random Forest pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RFP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "              (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "              (\"model\", RandomForestClassifier(n_estimators= 50, random_state= 100))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e774360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3= RFP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60790a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report( num_y_test,result_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d811737",
   "metadata": {},
   "source": [
    "#### XGBoost Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d353349",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),\n",
    "               (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", XGBClassifier(random_state= 100))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf6bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_4= XGP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a336f2",
   "metadata": {},
   "source": [
    "#### SVM Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),  \n",
    "               (\"feature_selection: \", SelectKBest(score_func=f_classif, k= 10)),\n",
    "               (\"model\", SVC(random_state= 100))\n",
    "              \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df679ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_5= SVP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c441f758",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Results after base_modeling:\n",
    "\n",
    "\n",
    "base_result= {\"DTP\": result_1, \"LRP\":result_2, \"RFP\": result_3, \"XGP\": result_4, \"SVP\":result_5}\n",
    "\n",
    "\n",
    "for key, value in base_result.items():\n",
    "    \n",
    "    print(f\"The performance of {key} is: \\n\\n\", classification_report(num_y_test, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184147dd",
   "metadata": {},
   "source": [
    "### Notes After Baseline Modeling:\n",
    "\n",
    "- All our models did relatively well in predicting non-churners or the No or 0 class \n",
    "\n",
    "however, for the \"Yes\" class:\n",
    "\n",
    "- Logistic regression did quite well in reducing false negatives (no classifying churners as non-churners)\n",
    "\n",
    "- Whiles SVM had the highest precision for the \"Yes\" class; therefore it did well in predicting false positives(not classifying non-churners as churner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0764e6",
   "metadata": {},
   "source": [
    "### Dealing with Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97ae86",
   "metadata": {},
   "source": [
    "##### In this section, we are going to see how functions like:\n",
    "\n",
    "- class_weight  for models that we will be using class weight, i will be appending \"_CW\" to the name to signify class_weight\n",
    "\n",
    "- SMOTE for models that we will be using class weight, i will be appending \"_SM\" to the name to signify SMOTE\n",
    "\n",
    "affect a model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ff4f5",
   "metadata": {},
   "source": [
    "### Using Class_Weight to Handle imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##initializing our class weight for each class\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=num_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ef8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "##assigning our weight to the respective class \n",
    "\n",
    "weight= dict(zip([0, 1], class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c298255",
   "metadata": {},
   "outputs": [],
   "source": [
    "##viewing the weight of each class \n",
    "\n",
    "weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e6893",
   "metadata": {},
   "source": [
    "#### Decision Tree with class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7abfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CW_DTP = Pipeline([\n",
    "    (\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "    (\"coltrans\", col_pipe),\n",
    "    (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "    (\"model\", DecisionTreeClassifier(\n",
    "        random_state= 100, \n",
    "        class_weight= weight))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab98871",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_DTP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4951dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_6= CW_DTP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc7a6ce",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646df9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_LRP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),  \n",
    "            (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", LogisticRegression(\n",
    "                   random_state=100,\n",
    "                   class_weight=weight))\n",
    "              \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e4f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_LRP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84023ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_7=CW_LRP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9c34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d283e",
   "metadata": {},
   "source": [
    "#### Random Forest Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_RFC= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "                (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\",RandomForestClassifier(random_state= 100, n_estimators= 50,\n",
    "                                               class_weight=weight))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bc1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_RFC.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_8= CW_RFC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc44afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d173024",
   "metadata": {},
   "source": [
    "#### XGBoost with Class Wieghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set \"scale_pos_weight\" based on class balance\n",
    "##we divie the majority class by the minority class\n",
    "\n",
    "pos_weight = (sum(df_drop[\"Churn\"]== \"No\"))/(sum(df_drop[\"Churn\"]== \"Yes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_XGB= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "                (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", XGBClassifier(random_state= 100,  scale_pos_weight=pos_weight))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_XGB.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_9= CW_XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae52e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a45a47",
   "metadata": {},
   "source": [
    "#### SVM with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CW_SVM= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "                (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", SVC( random_state= 100, class_weight=weight))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8966b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_SVM.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_10= CW_SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73970b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933dec91",
   "metadata": {},
   "source": [
    "#### Results after dealing with imbalance with class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5588e859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_cw= {\"Decision Tree\":result_1, \"Decision_Tree_CW\":result_6, \"Logistic Regression\":result_2, \n",
    "            \n",
    "            \"Logistic_Regression_CW\": result_7, \n",
    "            \n",
    "            \"Random Forest\": result_3, \"Random_Forest_CW\":result_8, \"XGB\":result_4, \"XGB_CW\":result_9, \n",
    "            \n",
    "            \"SVM\": result_5,\"SVM_CW\":result_10}\n",
    "\n",
    "for key, value in result_cw.items():\n",
    "    print(f\"Classification Report for {key}, is: \\n\\n\",(classification_report(num_y_test,value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c70dec",
   "metadata": {},
   "source": [
    "#### Notes: \n",
    "\n",
    "- After adding class weights, our models performed better in terms of improvement in the yes class predictions. There was an increase in the recalll for the yes class, which means the model had less false negatives which is something we want\n",
    "\n",
    "- Again SVM and Logistic Regression topped the charts. However, it is worth noting that while the recall of the Yes class increased the precision decreased, and this is a normal thing thanks to recall-precision trade off\n",
    "\n",
    "- overall, adding class weights improved the performance of the model for both classes as opposed to not using weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913859f2",
   "metadata": {},
   "source": [
    "### Trying our model with SMOTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e844d",
   "metadata": {},
   "source": [
    "#### SMOTE with DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f951f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTP_SM= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "               (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),# Perform feature selection\n",
    "               (\"smote\", SMOTE(random_state=100)),  # Apply SMOTE for oversampling\n",
    "               (\"model\", DecisionTreeClassifier(random_state= 100))  \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTP_SM.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_11= DTP_SM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cca97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d78558",
   "metadata": {},
   "source": [
    "#### SMOTE with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1a0725",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGR_SM= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "               (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),# Perform feature selection\n",
    "               (\"smote\", SMOTE(random_state=100)),  # Apply SMOTE for oversampling\n",
    "               (\"model\", LogisticRegression(random_state= 100))  \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGR_SM.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea2dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_12= LGR_SM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6324ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90c665",
   "metadata": {},
   "source": [
    "#### SMOTE with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_SM= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "               (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),# Perform feature selection\n",
    "               (\"smote\", SMOTE(random_state=100)),  # Apply SMOTE for oversampling\n",
    "               (\"model\",RandomForestClassifier(random_state= 100, n_estimators= 50))  \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_SM.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_13= RF_SM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b67f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084fac0",
   "metadata": {},
   "source": [
    "#### SMOTE with XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a91295",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_SM= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "               (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),# Perform feature selection\n",
    "               (\"smote\", SMOTE(random_state=100)),  # Apply SMOTE for oversampling\n",
    "               (\"model\", XGBClassifier(random_state= 100))  \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_SM.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f41b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_14= XGB_SM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67dab34",
   "metadata": {},
   "source": [
    "#### SMOTE with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaae533",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_SM= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe), \n",
    "               (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),# Perform feature selection\n",
    "               (\"smote\", SMOTE(random_state=100)),  # Apply SMOTE for oversampling\n",
    "               (\"model\", SVC(random_state= 100))  \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28973bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_SM.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173cac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_15= SVM_SM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e941b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88154726",
   "metadata": {},
   "source": [
    "### Comparing results of Class_weight vs SMOTE vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_result= {\"Decision Tree\":result_1, \"Decision Tree_SM\":result_11, \"Decision_Tree_CW\":result_6, \n",
    "               \n",
    "                   \"Logistic Regression\": result_2, \"Logistic Regression_SM\":result_12, \"Logistic_Regression_CW\": result_7, \n",
    "            \n",
    "             \"Random Forest\": result_3, \"Random Forest_SM\": result_13, \"Random_Forest_CW\":result_8, \n",
    "               \n",
    "               \"XGBoost\": result_4, \"XGB_SM\":result_14, \"XGB_CW\":result_9, \n",
    "                   \n",
    "                   \"SVM\": result_5, \"SVM_SM\": result_15,\"SVM_CW\":result_10}\n",
    "\n",
    "for key, value in imbalance_result.items():\n",
    "    \n",
    "    print(f\"Classification Report for {key}, is: \\n\\n\",(classification_report(num_y_test,value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546df500",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "- Balancing did improve the performance of our model, especially for the yes class. \n",
    "\n",
    "- At the end of this, we realized that the class-weights method did relatively better than the SMOTE method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c3b05",
   "metadata": {},
   "source": [
    "### Ensemble Techniques\n",
    "\n",
    "In this section, we will take a look at how various ensemble learning techniques affect our models performance. As we know certain models have low biases and high variance, whiles others have high bias and low variance, therefore, we will use the appopiriate ensemble technique to curb these.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0cf7a7",
   "metadata": {},
   "source": [
    "### Frame of work:\n",
    "\n",
    "- Bagging, works well fore models with high variance and low bias. These include algorithms such as: Random Forest, XGBoost, Decision Tree, and SVM\n",
    "\n",
    "- Boosting for models that have low variance and high bias like Logistic Regression\n",
    "\n",
    "The idea here is to see how these affect our models, and which to choose for our hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72edc9d2",
   "metadata": {},
   "source": [
    "### Bagging Decision Tree with Class Weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_DTP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),  \n",
    "            (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", BaggingClassifier(DecisionTreeClassifier(\n",
    "                   random_state=100,\n",
    "                   class_weight=weight), bootstrap_features= True,random_state= 100))\n",
    "              \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1de601",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_DTP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593041c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_16= en_DTP.predict(X_test)\n",
    "print(classification_report(num_y_test, result_16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074b734d",
   "metadata": {},
   "source": [
    "### Logistic Regression with Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128abed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_LRP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),  \n",
    "            (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", LogisticRegression(\n",
    "                   random_state=100,\n",
    "                   class_weight=weight))\n",
    "              \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_LRP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91145082",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_17= en_LRP.predict(X_test)\n",
    "print(classification_report(num_y_test, result_17))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa7fdd",
   "metadata": {},
   "source": [
    "### Bagging Random Forest with Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_RFP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),  \n",
    "            (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", BaggingClassifier(RandomForestClassifier(\n",
    "                   random_state=100,\n",
    "                   class_weight=weight), bootstrap_features= True,random_state= 100))\n",
    "              \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea4f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_RFP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e321b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_18= en_DTP.predict(X_test)\n",
    "print(classification_report(num_y_test, result_18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f6ce55",
   "metadata": {},
   "source": [
    "### Bagging XGBOOST with Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_XGB= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),  \n",
    "            (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", BaggingClassifier(XGBClassifier(\n",
    "                   random_state=100,\n",
    "                  scale_pos_weight=pos_weight), bootstrap_features= True,random_state= 100))\n",
    "              \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_XGB.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68c6689",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_19= en_XGB.predict(X_test)\n",
    "print(classification_report(num_y_test, result_19))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec24de9c",
   "metadata": {},
   "source": [
    "### Bagging of SVM with class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e852f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_SVM= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),  \n",
    "            (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", BaggingClassifier(SVC(\n",
    "                   random_state=100,\n",
    "                   class_weight=weight), bootstrap_features= True,random_state= 100))\n",
    "              \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2363e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_SVM.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca38ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_20= en_SVM.predict(X_test)\n",
    "print(classification_report(num_y_test, result_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e960ba",
   "metadata": {},
   "source": [
    "### Ensemble Result Comparison:\n",
    "\n",
    "- In this section, we will be comparing the result of our base model, our ensembled model, and our classweight without ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1122ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imbalance_result= {\"Decision Tree\":result_1, \"Decision_Tree_CW\":result_6, \"Decision Tree_en\":result_16,  \n",
    "               \n",
    "                   \"Logistic Regression\": result_2, \"Logistic_Regression_CW\": result_7, \"Logistic Regression_en\":result_17,  \n",
    "            \n",
    "             \"Random Forest\": result_3,\"Random_Forest_CW\":result_8,  \"Random Forest_en\": result_18, \n",
    "               \n",
    "               \"XGBoost\": result_4,\"XGB_CW\":result_9,  \"XGB_en\":result_18, \n",
    "                   \n",
    "                   \"SVM\": result_5,\"SVM_CW\":result_10, \"SVM_en\": result_20}\n",
    "\n",
    "for key, value in imbalance_result.items():\n",
    "    \n",
    "    print(f\"Classification Report for {key}, is: \\n\\n\",(classification_report(num_y_test,value)))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc509e7",
   "metadata": {},
   "source": [
    "### Notes after Ensembling:\n",
    "\n",
    "- Our models prediction for the Yes class greatly improved as we balanced the weights and used ensemble methods.\n",
    "\n",
    "- The base model for SVM did well by having the highest precision for the Yes class, while Logistic Regression with weights did well by having the highest recall for the Yes class\n",
    "\n",
    "In summary:\n",
    "\n",
    "- The class_weights imbalance handling method performed better than SMOTE \n",
    "\n",
    "- Overall, Logistic Regression and SVM topped the chart, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660ee6d",
   "metadata": {},
   "source": [
    "### Using Stacking to Create a Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee73a52",
   "metadata": {},
   "source": [
    "From our initial modelling, we realized that the base model for SVM did well, while the balanced model for Logistic Regression did well. Therefore, we will like to combine them to see how well these two will do together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##building our stacking classifier\n",
    "\n",
    "# Define the stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"logistic\", LogisticRegression(\n",
    "                   random_state=100,\n",
    "                   class_weight=weight)),\n",
    "        (\"svm\", SVC(random_state=100))\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(\n",
    "                   random_state=100, class_weight=weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeaacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_LRP= Pipeline([(\"spaceImputer\", SpaceImputer(remove_space)),\n",
    "               (\"coltrans\", col_pipe),  \n",
    "            (\"feature_selection\", SelectKBest(score_func=f_classif, k=10)),\n",
    "               (\"model\", stacking_clf)\n",
    "              \n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e02eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_LRP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fa920",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_21= st_LRP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, result_17))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219028cf",
   "metadata": {},
   "source": [
    "### Results after stacking:\n",
    "\n",
    "- There was an increase in the f-1 score and accuracy of our stacked model by 1 percent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf14d3",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda62ff",
   "metadata": {},
   "source": [
    "From our modeling, Logistic regression stood out, when we considered the recall and relative precision of the Yes class (Churners). So, what we will do here is to run a Grid_search CV to find the best hyperparameters for our model to increase its performance. \n",
    "\n",
    "#### What will we do?\n",
    "\n",
    "- We will perform a hyperparameter gridsearch on just the model then find the best parameters, and then add it to our pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd778a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce585f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "###creating the params\n",
    "\n",
    "params = {\n",
    "    \"model__penalty\": [\"l1\", \"l2\", \"elasticnet\", None],\n",
    "    \"model__C\": np.logspace(-4, 4, 20),\n",
    "    \"model__intercept_scaling\": [1, 2, 3, 4, 5],\n",
    "    \"model__solver\": [\"lbfgs\", \"liblinear\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    \"model__max_iter\": [100, 1200, 2000, 3000],\n",
    "    \"model__random_state\": [24, 42, 57, 100, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08872040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db005115",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_HPT= RandomizedSearchCV(estimator=CW_LRP, param_distributions=params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_HPT.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = Random_HPT.best_params_\n",
    "best_score = Random_HPT.best_score_\n",
    "cv_results = Random_HPT.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0195aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Parameters:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c2483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CW_LRP.set_params(model__solver='sag',\n",
    "                  model__random_state= 24,\n",
    "                  model__penalty='l2',\n",
    "                  model__max_iter=3000,\n",
    "                  model__intercept_scaling=4,\n",
    "                  model__C=0.08858667904100823)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f57e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "CW_LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b71e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CW_LRP.fit(X_train, num_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result= CW_LRP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1584b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(num_y_test, final_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693eafb",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# Specify the dependent variable and independent variables\n",
    "dependent_variable = 'Churn'\n",
    "independent_variable = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', \n",
    "                        'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                        'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n",
    "                        'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# Perform ANOVA for each independent variable\n",
    "for iv in independent_variable:\n",
    "    formula = f\"{dependent_variable} ~ C({iv})\"\n",
    "    model = ols(formula, data=df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    print(f\"ANOVA for {iv}\")\n",
    "    print(anova_table)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602027cb",
   "metadata": {},
   "source": [
    "-The p-value (PR(>F)) for \"gender\" is 0.469905. Interpretation: The p-value is greater than the typical significance level of 0.05, indicating that there is no statistically significant difference in the \"Churn\" variable based on gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebfb263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
